
# ğŸ›°ï¸ Real-Time People Access Analytics and Anomaly Detection

## âš™ï¸ Tech Stack

| Tool            | Purpose                          |
|-----------------|----------------------------------|
| ![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python) | Core scripting language             |
| ![Kafka](https://img.shields.io/badge/Apache%20Kafka-streaming-black?logo=apachekafka) | Data streaming between layers       |
| ![InfluxDB](https://img.shields.io/badge/InfluxDB-timeseries-blue?logo=influxdb) | Time-series database for events     |
| ![MongoDB](https://img.shields.io/badge/MongoDB-NoSQL-green?logo=mongodb) | NoSQL storage for raw/clean/history |
| ![Grafana](https://img.shields.io/badge/Grafana-dashboard-orange?logo=grafana) | Dashboards and alerts               |
| ![Docker](https://img.shields.io/badge/Docker-container-blue?logo=docker) | Containerization                    |
| ![VS Code](https://img.shields.io/badge/VSCode-IDE-blue?logo=visualstudiocode) | Development environment             |
| ![Git](https://img.shields.io/badge/Git-version--control-black?logo=git) | Version control                     |



## ğŸ“¦ Project Structure

```

â”œâ”€â”€ alerts_tests/ # Scripts to simulate alert triggering
â”‚ â”œâ”€â”€ test_never_exited.py
â”‚ â”œâ”€â”€ test_night_time.py
â”‚ â””â”€â”€ test_rapid_reuse.py
â”‚
â”œâ”€â”€ dashboard/ # Grafana configuration
â”‚ â”œâ”€â”€ Anomaly Detection.yaml
â”‚ â””â”€â”€ People Access Tracking-<ID>.json
â”‚
â”œâ”€â”€ data/ # Place your Excel data files here
â”œâ”€â”€ logs/ # Logs saved from each pipeline
â”‚
â”œâ”€â”€ mongo-data/ 
â”‚
â”œâ”€â”€ pipelines/ # Core pipeline scripts
â”‚ â”œâ”€â”€ detect_entry_exit_events.py
â”‚ â”œâ”€â”€ influx_write_events.py
â”‚ â”œâ”€â”€ ingest_raw_events.py
â”‚ â””â”€â”€ preprocess_clean_events.py
â”‚
â”œâ”€â”€ utils/ # Utility modules
â”‚ â”œâ”€â”€ config.py # Main settings
â”‚ â”œâ”€â”€ kafka_utils.py
â”‚ â”œâ”€â”€ logging_utils.py
â”‚ â”œâ”€â”€ mongo_utils.py
â”‚ â””â”€â”€ scoring_utils.py
â”‚
â”œâ”€â”€ main.py # Launches the whole pipeline
â”œâ”€â”€ docker-compose.yml # Docker setup (InfluxDB, Kafka, Grafana)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md


```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Ghantoos7/RealTime-Access-Tracking
cd RealTime-Access-Tracking
````

### 2. Prepare Data

* Create a `data/` folder in the root directory.
* Place your Excel files containing access data inside it.

### 3. Create InfluxDB Bucket

* Go to your InfluxDB UI â†’ Buckets â†’ Create new
* Name it: `rfid_events`

### 4. Setup Python Environment

```bash
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows
pip install -r requirements.txt
```

Ensure `requirements.txt` includes:

```
pandas
kafka-python
pymongo
influxdb-client
```

### 5. Update Configuration

Edit `utils/config.py`:

* Replace `INFLUXDB_TOKEN` with your token from InfluxDB.
* Optionally configure MongoDB and Kafka settings.

### 6. Start Services with Docker

```bash
docker-compose up -d
```

This launches:


* Grafana (localhost:3000)
* KafkaUI (localhost:8081)
* InfluxDB (localhost:8086)
* MongoDB (localhost:27017)

---

## ğŸ“Š Setup Grafana

1. Go to `http://localhost:3000`
2. Log in (`admin` / `admin`)
3. Add InfluxDB as a data source:

   * URL: `http://influxdb:8086` 
   * Token: Use your configured `INFLUXDB_TOKEN`
   * Bucket: `rfid_events`
4. Import the dashboard JSON:

   * Go to Dashboards â†’ Import â†’ Upload `dashboard/People Access Tracking-1746467770355.json.json`

---

## âš ï¸ Configure Alerts

1. Open Grafana â†’ Alerting â†’ Alert rules
2. Import rules from `dashboard/Anomaly Detection.yaml`
3. Ensure notification channels (email, Slack) are configured properly
4. Test alerts by running the data simulation script

---

## ğŸ§ª Running the Pipeline

```bash
python main.py
```

This will launch the entire pipeline:

* Ingest Excel â†’ Kafka
* Clean â†’ Kafka
* Detect â†’ Kafka
* Write â†’ InfluxDB
* Store in MongoDB

---

## ğŸ§  Useful Tips

* All logs are written to `rfid_stream.log` for easier debugging.
* Each processing layer logs events, exceptions, and stats.
* MongoDB contains raw, clean, and detected event collections for history/auditing.
* Use Grafana for real-time anomaly monitoring.

---

## ğŸ§¼ Stopping Everything

```bash
docker-compose down
```

---

## ğŸ“ License

This project is licensed under MIT License.

---
